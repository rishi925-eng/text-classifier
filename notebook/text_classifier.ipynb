{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0035631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install / upgrade dependencies (run this cell FIRST)\n",
    "!pip install -q \"transformers[torch]\" \"accelerate>=0.26.0\" datasets scikit-learn pandas\n",
    "\n",
    "# If you still see a torch import error, uncomment and run the appropriate torch install for your platform:\n",
    "# For Linux/CUDA (example): !pip install -q torch --index-url https://download.pytorch.org/whl/cu118\n",
    "# For CPU-only: !pip install -q torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "435c2c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Desktop\\New civictext\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch available: 2.8.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "\n",
    "print(\"torch available:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d17e033e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {'streetlight': 0, 'garbage': 1, 'potholes': 2}\n",
      "Loaded dataset shape: (1267, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The streetlight at the main intersection is no...</td>\n",
       "      <td>streetlight</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There's a massive pile of garbage near the com...</td>\n",
       "      <td>garbage</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A deep pothole on Station Road is causing traf...</td>\n",
       "      <td>potholes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hamari gali ki light pichle 10 din se kharab hai.</td>\n",
       "      <td>streetlight</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Market me har taraf gandagi faili hui hai.</td>\n",
       "      <td>garbage</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text        label  label_id\n",
       "0  The streetlight at the main intersection is no...  streetlight         0\n",
       "1  There's a massive pile of garbage near the com...      garbage         1\n",
       "2  A deep pothole on Station Road is causing traf...     potholes         2\n",
       "3  Hamari gali ki light pichle 10 din se kharab hai.  streetlight         0\n",
       "4         Market me har taraf gandagi faili hui hai.      garbage         1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your dataset (CSV with 'text' and 'label' columns)\n",
    "df = pd.read_csv(\"../data/textdata.csv\")\n",
    "\n",
    "# Allowed labels (text form)\n",
    "allowed_labels = [\"streetlight\", \"garbage\", \"potholes\"]\n",
    "\n",
    "# Filter only rows with allowed labels and keep text labels in df\n",
    "df = df[df[\"label\"].isin(allowed_labels)].reset_index(drop=True)\n",
    "\n",
    "# Create mapping for training (used internally)\n",
    "label2id = {label: idx for idx, label in enumerate(allowed_labels)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "# Convert label column to integer IDs for training\n",
    "df[\"label_id\"] = df[\"label\"].map(label2id)\n",
    "\n",
    "print(\"Label mapping:\", label2id)\n",
    "print(\"Loaded dataset shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cd1530b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: garbage\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'label_id' column from df\n",
    "df_no_label_id = df.drop(columns=['label_id'])\n",
    "\n",
    "# Predict label for a given text using the trained model\n",
    "def predict_label(text):\n",
    "  inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "  with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class_id = torch.argmax(logits).item()\n",
    "  return id2label[predicted_class_id]\n",
    "\n",
    "# Example usage\n",
    "example_text = \"My internet is not working properly\"\n",
    "predicted_label = predict_label(example_text)\n",
    "print(f\"Predicted label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14664097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the integer label column for training (must be named 'label' for HuggingFace Trainer)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_dataset = Dataset.from_pandas(train_df[['text', 'label_id']].rename(columns={'label_id': 'label'}))\n",
    "test_dataset = Dataset.from_pandas(test_df[['text', 'label_id']].rename(columns={'label_id': 'label'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "743d7a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1013/1013 [00:00<00:00, 9520.89 examples/s]\n",
      "Map: 100%|██████████| 254/254 [00:00<00:00, 6918.01 examples/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83caa202",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=len(label2id), id2label=id2label, label2id=label2id\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13752994",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../model/results\",\n",
    "    per_device_train_batch_size=4,  # Reduced batch size for faster training\n",
    "    per_device_eval_batch_size=4,   # Reduced batch size\n",
    "    num_train_epochs=1,             # Reduced to 1 epoch for faster training\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"../model/logs\",\n",
    "    logging_steps=50,               # Increased logging steps\n",
    "    report_to=None,                 # disable wandb/tensorboard auto logging\n",
    "    push_to_hub=False,\n",
    "    dataloader_pin_memory=False,    # Disable pin memory for CPU\n",
    "    save_steps=500,                 # Save less frequently\n",
    "    eval_steps=500,                 # Evaluate less frequently\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97fba32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='254' max='254' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [254/254 05:10, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.074500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=254, training_loss=0.01570136011447519, metrics={'train_runtime': 311.765, 'train_samples_per_second': 3.249, 'train_steps_per_second': 0.815, 'total_flos': 33547966979328.0, 'train_loss': 0.01570136011447519, 'epoch': 1.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    processing_class=tokenizer,  # Updated from tokenizer to processing_class\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e310571b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved in ../model/saved_model\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"../model/saved_model\")\n",
    "tokenizer.save_pretrained(\"../model/saved_model\")\n",
    "\n",
    "print(\"✅ Model saved in ../model/saved_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b922b11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'The streetlight near my home is broken', 'predicted_category': 'streetlight', 'confidence': 0.9999548196792603}\n",
      "{'text': 'There is garbage dumped on the roadside', 'predicted_category': 'garbage', 'confidence': 0.9999219179153442}\n",
      "{'text': 'The road has a big pothole causing accidents', 'predicted_category': 'potholes', 'confidence': 0.9999740123748779}\n",
      "{'text': 'road me gadhha hai', 'predicted_category': 'potholes', 'confidence': 0.9999723434448242}\n",
      "{'text': 'streetlight khrab hai', 'predicted_category': 'streetlight', 'confidence': 0.9999518394470215}\n",
      "{'text': 'kachra faila hua hai', 'predicted_category': 'garbage', 'confidence': 0.9999144077301025}\n",
      "{'text': 'tuta hua road hai', 'predicted_category': 'potholes', 'confidence': 0.9999680519104004}\n",
      "{'text': 'gadha hai', 'predicted_category': 'potholes', 'confidence': 0.9994914531707764}\n",
      "{'text': 'kachra faila hai road pr', 'predicted_category': 'garbage', 'confidence': 0.9998955726623535}\n",
      "{'text': 'tuta hua road hai', 'predicted_category': 'potholes', 'confidence': 0.9999680519104004}\n",
      "{'text': 'gadha hai', 'predicted_category': 'potholes', 'confidence': 0.9994914531707764}\n",
      "{'text': 'kachra faila hai road pr', 'predicted_category': 'garbage', 'confidence': 0.9998955726623535}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load saved model + tokenizer\n",
    "model_path = \"../model/saved_model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Function to predict category\n",
    "def classify_issue(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        predicted_class_id = probs.argmax().item()\n",
    "    predicted_label = model.config.id2label[predicted_class_id]\n",
    "    return {\"text\": text, \"predicted_category\": predicted_label, \"confidence\": probs[0][predicted_class_id].item()}\n",
    "\n",
    "# 🔹 Test the classifier\n",
    "examples = [\n",
    "    \"The streetlight near my home is broken\",\n",
    "    \"There is garbage dumped on the roadside\",\n",
    "    \"The road has a big pothole causing accidents\",\n",
    "    \"road me gadhha hai\",\n",
    "    \"streetlight khrab hai\",\n",
    "    \"kachra faila hua hai\",\n",
    "    \"tuta hua road hai\",\n",
    "    \"gadha hai\",\n",
    "    \"kachra faila hai road pr\"\n",
    "\n",
    "]\n",
    "\n",
    "for text in examples:\n",
    "    print(classify_issue(text))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
